{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8dc936f",
   "metadata": {},
   "source": [
    "# Construcci√≥n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bab41ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬øCUDA disponible? True\n",
      "GPU actual: NVIDIA GeForce RTX 4070 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"¬øCUDA disponible?\", torch.cuda.is_available())\n",
    "print(\"GPU actual:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22fe7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm  # aseg√∫rate de tener esto importado arriba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b3cd6f",
   "metadata": {},
   "source": [
    "Crear dataset personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "630d86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class TensorVideoDataset(Dataset):\n",
    "    def __init__(self, tensor_paths, labels):\n",
    "        self.tensor_paths = tensor_paths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = time.time()\n",
    "        video_tensor = torch.load(self.tensor_paths[idx])\n",
    "        label = torch.tensor(self.labels[idx]).float()\n",
    "        #print(f\"‚è± Tiempo carga tensor: {time.time() - start:.2f} s\")\n",
    "        return video_tensor, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb899434",
   "metadata": {},
   "source": [
    "Cargar archivos .pt y generar las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af31ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ruta donde guardaste los tensores\n",
    "tensor_dir = Path(\"C:/Users/Hermanos/Desktop/Proyecto Deepfake/preprocesados\")\n",
    "\n",
    "# Cargar todos los tensores\n",
    "all_tensors = list(tensor_dir.glob(\"*.pt\"))\n",
    "\n",
    "# Etiquetar: 'original' = 0 (real), todo lo dem√°s = 1 (fake)\n",
    "tensor_labels = [0 if \"original\" in str(p.name).lower() else 1 for p in all_tensors]\n",
    "\n",
    "# Dividir en train, val y test (70/15/15)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(all_tensors, tensor_labels, test_size=0.3, stratify=tensor_labels, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160896e6",
   "metadata": {},
   "source": [
    "Crear dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "700792e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_ds = TensorVideoDataset(X_train, y_train)\n",
    "val_ds = TensorVideoDataset(X_val, y_val)\n",
    "test_ds = TensorVideoDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,  pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False,  pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb59c3c6",
   "metadata": {},
   "source": [
    "Definir el modelo EfficientNet fine-tuneado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f3d482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b0\n",
    "import torch.nn as nn\n",
    "\n",
    "class FramewiseEfficientNet(nn.Module):\n",
    "    def __init__(self, sequence_length=16, dropout=0.4):\n",
    "        super(FramewiseEfficientNet, self).__init__()\n",
    "        self.backbone = efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: [B, T, C, H, W]\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        feats = self.backbone(x)\n",
    "        feats = feats.view(B, T, -1).mean(1)\n",
    "        return self.classifier(feats).view(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cdc06f",
   "metadata": {},
   "source": [
    "Funci√≥n train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67512432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_model(model, train_loader, val_loader, test_loader,\n",
    "                lr=1e-4, epochs=10, device='cuda', save_path='best_model.pt'):\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_auc = 0.0\n",
    "\n",
    "    def evaluate(loader):\n",
    "        model.eval()\n",
    "        y_true, y_scores = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device).float()\n",
    "                logits = model(x)\n",
    "                probs = torch.sigmoid(logits)\n",
    "                y_scores.extend(probs.cpu().numpy())\n",
    "                y_true.extend(y.cpu().numpy())\n",
    "\n",
    "        y_scores = np.array(y_scores)\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = (y_scores > 0.5).astype(int)\n",
    "\n",
    "        auc = roc_auc_score(y_true, y_scores)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "        return {\n",
    "            'auc': auc,\n",
    "            'accuracy': acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for i, (x, y) in enumerate(tqdm(train_loader, desc=f\"üîÅ Epoch {epoch}/{epochs}\")):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).float()\n",
    "\n",
    "            # Solo imprimir en la primera iteraci√≥n\n",
    "            if epoch == 1 and i == 0:\n",
    "                print(f\"x device: {x.device} | y device: {y.device} | model device: {next(model.parameters()).device}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        val_metrics = evaluate(val_loader)\n",
    "        print(f\"üìò Epoch {epoch}/{epochs} | Loss: {epoch_loss:.4f} | Val AUC: {val_metrics['auc']:.4f} | Acc: {val_metrics['accuracy']:.4f}\")\n",
    "\n",
    "        # Guardar el mejor modelo\n",
    "        if val_metrics['auc'] > best_auc:\n",
    "            best_auc = val_metrics['auc']\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"‚úÖ Nuevo mejor modelo guardado.\")\n",
    "\n",
    "    # Evaluar el mejor modelo en test\n",
    "    print(\"\\nüîç Evaluando el mejor modelo en el conjunto de prueba...\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    test_metrics = evaluate(test_loader)\n",
    "\n",
    "    print(f\"\\nüìä Resultados en Test:\")\n",
    "    for k, v in test_metrics.items():\n",
    "        print(f\"{k.capitalize()}: {v:.4f}\")\n",
    "\n",
    "    return test_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64da304d",
   "metadata": {},
   "source": [
    "Ejecutar el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c87732bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Epoch 1/10:   0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x device: cuda:0 | y device: cuda:0 | model device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [08:54<00:00,  6.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Epoch 1/10 | Loss: 30.1072 | Val AUC: 0.8539 | Acc: 0.8664\n",
      "‚úÖ Nuevo mejor modelo guardado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [09:01<00:00,  7.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Epoch 2/10 | Loss: 16.6393 | Val AUC: 0.9256 | Acc: 0.9084\n",
      "‚úÖ Nuevo mejor modelo guardado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [09:00<00:00,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Epoch 3/10 | Loss: 8.4683 | Val AUC: 0.9025 | Acc: 0.9160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [08:56<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Epoch 4/10 | Loss: 6.1315 | Val AUC: 0.9092 | Acc: 0.9084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [08:56<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Epoch 5/10 | Loss: 2.1663 | Val AUC: 0.9511 | Acc: 0.9237\n",
      "‚úÖ Nuevo mejor modelo guardado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [08:56<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Epoch 6/10 | Loss: 3.2146 | Val AUC: 0.9396 | Acc: 0.9046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [08:56<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Epoch 7/10 | Loss: 4.4203 | Val AUC: 0.9238 | Acc: 0.9046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [08:56<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Epoch 8/10 | Loss: 3.5700 | Val AUC: 0.9103 | Acc: 0.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [08:56<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Epoch 9/10 | Loss: 1.5499 | Val AUC: 0.9208 | Acc: 0.9046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [08:56<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Epoch 10/10 | Loss: 1.9455 | Val AUC: 0.9262 | Acc: 0.9351\n",
      "\n",
      "üîç Evaluando el mejor modelo en el conjunto de prueba...\n",
      "\n",
      "üìä Resultados en Test:\n",
      "Auc: 0.9207\n",
      "Accuracy: 0.9163\n",
      "Precision: 0.9432\n",
      "Recall: 0.9600\n",
      "F1: 0.9515\n"
     ]
    }
   ],
   "source": [
    "model = FramewiseEfficientNet()\n",
    "\n",
    "# üëá AQUI colocas la prueba del batch\n",
    "#print(\"üîç Probando un batch...\")\n",
    "#x_test, y_test = next(iter(train_loader))\n",
    "#print(f\"Lote cargado correctamente. Forma: {x_test.shape}\")\n",
    "\n",
    "# Si pasa la prueba, se entrena el modelo\n",
    "metrics = train_model(\n",
    "    model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    lr=1e-4,\n",
    "    epochs=10,\n",
    "    save_path=\"modelo_finetuneado.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f919c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Resultados en el conjunto de prueba:\n",
      "AUC:       0.9511\n",
      "Accuracy:  0.9237\n",
      "Precision: 0.9476\n",
      "Recall:    0.9644\n",
      "F1 Score:  0.9559\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Evaluaci√≥n en el conjunto de prueba\n",
    "# ============================\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "model = FramewiseEfficientNet()\n",
    "model.load_state_dict(torch.load(\"modelo_finetuneado.pt\"))\n",
    "model = model.to(device)  # üí• Muy importante mover el modelo a GPU DESPU√âS de cargar pesos\n",
    "model.eval()\n",
    "\n",
    "\n",
    "y_true, y_scores = [], []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).float()\n",
    "        logits = model(x)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        y_scores.extend(probs.cpu().numpy())\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "\n",
    "y_scores = np.array(y_scores)\n",
    "y_true = np.array(y_true)\n",
    "y_pred = (y_scores > 0.5).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_true, y_scores)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "print(\"\\nüìä Resultados en el conjunto de prueba:\")\n",
    "print(f\"AUC:       {auc:.4f}\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
